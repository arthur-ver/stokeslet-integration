from alive_progress import alive_bar
import numpy as np
import quadpy
from anytree import Node
from .mesh import subdivide_element, circle_segment_mesh, reshape_meshpy_for_quadpy

_DEG_ = [3, 7, 12]


def s_zz(x_f: np.ndarray, x_s: np.ndarray, lam: np.complex64):
    """Calculates the Stokeslet's zz-component

    Args:
        x_f: field point    `shape (3,)`
        x_s: source points  `shape (n_points, 3)`
        lam: lambda

    Returns:
        Stokeslet's zz-component `shape (n_points,)`
    """
    x_bar = x_f - x_s
    r = np.linalg.vector_norm(x_bar, axis=1)
    R = lam * r
    A = 2 * np.exp(-R) * (1 + 1 / R + 1 / R**2) - 2 / R**2  # eq. (2.11)
    B = -2 * np.exp(-R) * (1 + 3 / R + 3 / R**2) + 6 / R**2  # eq. (2.12)
    delta_ij = np.eye(3)[None, :, :]  # shape (1, 3, 3)
    x_bar_prod = np.einsum("ni,nj->nij", x_bar, x_bar)  # shape (N, 3, 3)
    S_ij = (
        1 / 8 / np.pi * (A / r)[:, None, None] * delta_ij
        + (B / r**3)[:, None, None] * x_bar_prod
    )  # eq. (2.10)

    return S_ij[:, 2, 2]  # S_zz (i,j -> 0=x, 1=y, 2=z)


def s_zz_proxy(x_f: np.ndarray, x_s: np.ndarray, lam: np.complex64):
    """Stokeslet proxy function for `quadpy`

    For each element (a set of corners/vertices) which is being integrated over,
    this function accepts a set of points generated by the given `quadpy` quadrature scheme,
    passes them to the Stokeslet function in correct shape, and reshapes the result back
    to `quadpy`'s expected shape.

    Args:
        x_f: field point      `shape (3,)`
        x_s: source points    `shape (2, n_elements, n_quadrature_points)`
        lam: lambda

    Returns:
        Stokeslet's zz-component `shape (n_elements, n_quadrature_points)`
    """
    x_s_reshaped = np.concatenate(
        [x_s, np.zeros((1, *x_s.shape[1:]))], axis=0
    )  # shape (3, n, p)
    # Reshape to (n_elements, 3)
    n_elements = x_s_reshaped.shape[1] * x_s_reshaped.shape[2]
    x_s_reshaped_flat = x_s_reshaped.transpose(1, 2, 0).reshape(n_elements, 3)
    # Apply the s_zz function
    s_zz_result = s_zz(x_f, x_s_reshaped_flat, lam)  # Shape: (n_elements, 3)
    return s_zz_result.reshape(
        x_s.shape[1], x_s.shape[2]
    )  # Reshape the output back to (n, p)


def refine_node(node) -> None:
    """Adds 4 children to parent node each containing a finer mesh element

    Args:
        node: Node of a non-converged mesh element
    """
    sub_elements = subdivide_element(node.element)  # returns list of 4 sub-mesh arrays
    for i, element in enumerate(sub_elements):
        Node(
            f"{node.name}/{i}",
            parent=node,
            element=element,
            I=None,
            converged=False,
        )


def integrate_over_elements_wo_singularity(
    elements: np.ndarray,
    x_f: np.ndarray,
    lam: np.complex64,
    eps: float,
) -> np.ndarray:
    """Computing Stokeslet integrals over rectangular mesh elements w/o singularity

    Args:
        elements: rectangle elements `shape (2, 2, n_elements, 2)`
        x_f: field point `shape (3,)`
        lam: lambda
        eps: relative error threshold

    Returns:
        integral values `shape (n_elements, )`
    """
    # Start with an empty tree (stored in root_nodes) for each original mesh element
    root_nodes = []
    n_elements = elements.shape[2]
    for i in range(n_elements):
        node = Node(
            f"{i}",
            element=elements[:, :, i : i + 1, :],
            I=None,
            converged=False,
        )
        root_nodes.append(node)
    # Assume all root nodes need to be refined
    nodes_to_refine = root_nodes.copy()
    # Loop until threshold is reached
    deg_index = 0
    with alive_bar(
        n_elements,
        manual=True,
        title="1. Computing Stokeslet integrals over mesh elements w/o singularity",
        title_length=72,
        bar=None,
        stats=False,
    ) as bar:
        while nodes_to_refine:
            if deg_index >= len(_DEG_):
                # Subdivide non-converged mesh elements into four elements, when max quadrature is reached
                nodes_to_refine_ = []
                for node in nodes_to_refine:
                    refine_node(node)
                    nodes_to_refine_.extend(list(node.children))
                nodes_to_refine = nodes_to_refine_
                deg_index = 0  # Reset quadrature degree index for new refined elements
                continue

            elements = np.concatenate(
                [node.element for node in nodes_to_refine], axis=2
            )  # Each node.element has shape (2, 2, 1, 2), so the resulting array will be (2, 2, n_elements, 2)

            # Compute integrals
            scheme_finer = quadpy.c2.get_good_scheme(_DEG_[deg_index])
            I_finer = scheme_finer.integrate(
                lambda x_s: s_zz_proxy(x_f, x_s, lam), elements
            )

            # Check which integrals converged and update integral values of nodes (mesh elements)
            nodes_to_refine_ = []
            for i, node in enumerate(nodes_to_refine):
                I = I_finer[i]
                if node.I is not None:
                    rel_error = np.abs(node.I - I) / np.abs(I)
                else:
                    rel_error = np.inf

                if rel_error <= eps:
                    node.converged = True
                else:
                    nodes_to_refine_.append(node)

                node.I = I

            nodes_to_refine = nodes_to_refine_
            deg_index += 1

            # Update progress bar
            remaining_root_nodes = set()
            for node in nodes_to_refine:
                remaining_root_nodes.add(node.root.name)
            n_remaining = n_elements - len(remaining_root_nodes)
            bar(np.floor(n_remaining / n_elements * 100) / 100)

    # Sum split elements back up
    I_final = np.zeros(n_elements + 1, dtype=np.complex64)
    for i, node in enumerate(root_nodes):
        I_final[i] = np.sum(leaf.I for leaf in node.leaves)

    return I_final


def integrate_over_segment(
    type: str,
    dx: float,
    dy: float,
    r: float,
    eps: float,
    lam: np.complex64,
    n_arc_points: int,
    n_triangles: int,
    factor: float,
) -> float:
    """Computes Stokeslet integral over a circle segment

    Args:
        type: "top" | "left"
        dx: mesh element length (non-dim)
        dy: mesh element width (non-dim)
        r: radius
        eps: relative error threshold
        lam: lambda
        n_arc_points: number of points for defining the arc (more points -> smoother arc)
        n_triangles: number of triangles
        factor: each time integral convergence for a circle segment is not achieved, n_triangles will be multiplied by this factor

    Returns:
        integral value
    """
    converged = False
    while converged is not True:
        mesh = circle_segment_mesh(type, dx, dy, r, n_arc_points, n_triangles)
        n_triangles *= factor
        mesh_finer = circle_segment_mesh(type, dx, dy, r, n_arc_points, n_triangles)

        elements = reshape_meshpy_for_quadpy(mesh)
        elements_finer = reshape_meshpy_for_quadpy(mesh_finer)

        scheme = quadpy.t2.get_good_scheme(5)
        I = np.sum(
            scheme.integrate(
                lambda x_s: s_zz_proxy(np.array([0, 0, 0]), x_s, lam), elements
            )
        )
        I_finer = np.sum(
            scheme.integrate(
                lambda x_s: s_zz_proxy(np.array([0, 0, 0]), x_s, lam), elements_finer
            )
        )

        rel_error = np.abs(I_finer - I) / np.abs(I)
        if rel_error <= eps:
            converged = True

    return I


def integrate_over_element_w_singularity(
    dx: float,
    dy: float,
    eps: float,
    lam: np.complex64,
    n_arc_points: int,
    n_triangles: int,
    factor: float,
) -> float:
    """Computes Stokeslet integral over mesh element w/ singularity at the center

    Args:
        dx: mesh element length (non-dim)
        dy: mesh element width (non-dim)
        eps: relative error threshold
        lam: lambda
        n_arc_points: number of points for defining the arc (more points -> smoother arc)
        n_triangles: number of triangles
        factor: each time integral convergence for a circle segment is not achieved, n_triangles will be multiplied by this factor

    Returns:
        integral value
    """
    r = np.sqrt(dx**2 + dy**2) / 2
    # Integrate over top segment
    with alive_bar(
        2,
        manual=True,
        title="2. Computing Stokeslet integral over mesh element w/ singularity",
        title_length=72,
        bar=None,
        stats=False,
    ) as bar:
        I_top_segment = integrate_over_segment(
            "top", dx, dy, r, eps, lam, n_arc_points, n_triangles, factor
        )
        bar(0.5)
        # Integrate over left segment
        I_left_segment = integrate_over_segment(
            "left", dx, dy, r, eps, lam, n_arc_points, n_triangles, factor
        )
        bar(1)
        # Analytic integral value over circle region
        I_analytic = (
            -(4 * np.pi * ((lam * r + 1) * np.exp(-lam * r) - 1) / (lam**2 * r))
            / 8
            / np.pi
        )
        # Subtract 2x segments from analytic value
        I = I_analytic - 2 * I_top_segment - 2 * I_left_segment

    return I


def map_indices(start: tuple[int, int], end: tuple[int, int], ny: int, nx: int):
    """Maps mirrored row and column indices

    Args:
        start: tuple (row, col) of start indices
        end: tuple (row, col) of end indices
        ny: number of rows
        nx: number of columns

    Returns:
        mapped row indices and column indices
    """
    rows = np.arange(start[0], end[0], dtype=np.int32)[:, None]
    cols = np.arange(start[1], end[1], dtype=np.int32)[None, :]
    rows = np.minimum(rows, 2 * ny - 2 - rows, out=rows)
    cols = np.minimum(cols, 2 * nx - 2 - cols, out=cols)
    return rows, cols


def padded_mesh_cutout(
    I: np.ndarray, start: tuple[int, int], end: tuple[int, int], mem_priority: bool
):
    """Returns a cutout from the padded mesh of Stokeslet integral values

    Args:
        I: pre-computed Stokeslet integral quarter
        start: tuple (row, col) of start indices
        end: tuple (row, col) of end indices
        mem_priority:

    Returns:
       Stokeslet integral values
    """
    if not mem_priority:
        return I[start[0] : end[0], start[1] : end[1]]
    else:
        mapped_rows, mapped_cols = map_indices(start, end, *I.shape)
        return I[mapped_rows, mapped_cols]


def assemble_hydrodynamic_func_matrix(
    I: np.ndarray,
    mem_priority: bool,
    p_shape: tuple[int, int],
    x_partitions: list[int] | None = None,
    y_partitions: list[int] | None = None,
) -> tuple[np.ndarray, int, int]:
    """Assembles hydrodynamic function matrix from Stokeslet integrals

    Args:
        I: Stokeslet integral matrix
        mem_priority:
        p_shape: tuple (rows, cols)
        x_partitions:
        y_partitions:

    Returns:
        hydrodynamic function matrix
    """
    rows, cols = p_shape
    s_dim = rows * cols
    S = np.empty((s_dim, s_dim), dtype=np.complex64)

    interpolate = (
        True if x_partitions is not None or y_partitions is not None else False
    )

    if interpolate:
        col_starts = np.r_[0, np.cumsum(x_partitions)[:-1]]
        row_starts = np.r_[0, np.cumsum(y_partitions)[:-1]]

    n_compute_elements = (
        s_dim // 2 + 1 if not interpolate else s_dim
    )  # if no edge partitioning is used, only half of elements need to be computed, and the rest can be mirrored

    x_f = (
        I.shape[0],  # y
        I.shape[1],  # x
    )  # field point is located in the center of the (2*nx - 1)x(2*ny - 1) padded mesh

    if not mem_priority:
        # Expand I into a (2*nx - 1)x(2*ny - 1) matrix (padded mesh)
        I = np.concatenate((I, np.flip(I[:, :-1], axis=1)), axis=1)
        I = np.concatenate((I, np.flip(I[:-1, :], axis=0)), axis=0)

    with alive_bar(
        n_compute_elements,
        title="3. Assembling hydrodynamic function matrix from Stokeslet integrals",
        title_length=72,
        bar=None,
    ) as bar:
        ij = 0
        for i in range(rows):
            for j in range(cols):
                if interpolate:
                    row_start, row_end = (
                        x_f[0] - 1 - row_starts[i] - y_partitions[i] // 2,
                        2 * x_f[0] - 1 - row_starts[i] - y_partitions[i] // 2,
                    )
                    col_start, col_end = (
                        x_f[1] - 1 - col_starts[j] - x_partitions[j] // 2,
                        2 * x_f[1] - 1 - col_starts[j] - x_partitions[j] // 2,
                    )
                else:
                    row_start, row_end = (
                        x_f[0] - 1 - i,
                        2 * x_f[0] - 1 - i,
                    )
                    col_start, col_end = (
                        x_f[1] - 1 - j,
                        2 * x_f[1] - 1 - j,
                    )

                I_cutout = padded_mesh_cutout(
                    I, (row_start, col_start), (row_end, col_end), mem_priority
                )

                if interpolate:
                    I_interpolated = np.add.reduceat(
                        np.add.reduceat(
                            I_cutout, row_starts, axis=0, dtype=np.complex64
                        ),
                        col_starts,
                        axis=1,
                        dtype=np.complex64,
                    )

                    S[ij, :] = I_interpolated.flatten()
                else:
                    S[ij, :] = I_cutout.flatten()

                ij += 1
                bar()

                if not interpolate and ij == n_compute_elements:
                    # Mirror second half (both horizontally and vertically)
                    center_index = s_dim // 2
                    start_index = center_index + (s_dim % 2)
                    S[start_index:] = np.flip(S[:center_index], axis=(0, 1))
                    break
            else:
                continue
            break

    return S
